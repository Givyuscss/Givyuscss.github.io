I"r<h2 id="pca">PCA</h2>

<p>PCA主要是用于处理数据冗杂问题，功能是数据降维</p>

<h3 id="pca数学原理">PCA数学原理</h3>
<p>对于数据集<script type="math/tex">X,\forall x_i \in X, x \in \mathbb{R}^d</script>，每个数据都是d维的，d维特征过于冗杂，且大部分是无用的信息，因此，需要对其进行降维，提取中区分度大的特征，原数据集映射至低维空间。</p>

<p>需要用到的方法为基变换，一个mxn的矩阵，m个数据，每个数据n个特征，需要将其降维至k个特征，则需要n个k维基。</p>

<ul>
  <li>首先向量$x$在<script type="math/tex">\vec{v}</script>方向上的投影为：</li>
</ul>

<script type="math/tex; mode=display">\rho(x)=\frac{\vec{v}^Tx}{\|\vec{v}\|}</script>

<ul>
  <li>当$\vec{v}$是单位向量时，则投影为：</li>
</ul>

<script type="math/tex; mode=display">\rho(x)=\vec{v}^Tx</script>

<ul>
  <li>设数据集为<script type="math/tex">X_{m\times n}</script>,可将变化后的投影集体设为<script type="math/tex">Xv</script>，在各个方向上的投影点越分散，方差越大，则说明这个特征对与数据集保存的信息量越多</li>
  <li>在此之前，数据集每列特征进行去均值化处理，所以使得<script type="math/tex">\mu(X,v)=0</script></li>
  <li>而经过投影变化后的信息量为:</li>
</ul>

<script type="math/tex; mode=display">info(X,v)=\sigma^2(X,v)=\frac{1}{m}\sum^{m}_{i=1}(v^Tx_i-\mu)^2=\frac{1}{m}(Xv)^TXv=\frac{1}{m}v^TX^TXv</script>

<ul>
  <li>由于$X$是去均值后的矩阵，<script type="math/tex">\frac{1}{m}X^TX</script>即为<script type="math/tex">X</script>的协方差矩阵，记为C,则<script type="math/tex">info(X,v)=v^TCv</script></li>
  <li>又因为约束条件为$v$为单位向量，所以<script type="math/tex">v^Tv=1</script>，用拉格朗日乘子法将约束直接加入目标函数，则:</li>
</ul>

<script type="math/tex; mode=display">info(X,v)=v^TCv-\lambda(v^Tv-1)</script>

<ul>
  <li>对<script type="math/tex">info(X,v)求v偏导</script>，则:</li>
</ul>

<script type="math/tex; mode=display">\frac{\partial info(X,v)}{\partial v}=2Cv-2\lambda v=0</script>

<p>    则<script type="math/tex">Cv=\lambda v</script></p>

<ul>
  <li>该式符合矩阵特征值和特征向量的性质，可以的出此时满足条件的<script type="math/tex">\lambda,v</script>即为协方差矩阵的特征值和对应的特征向量。</li>
  <li>将其带入<script type="math/tex">info(X,v)=v^TCv</script>得到<script type="math/tex">info(X,v)=v^T\lambda v=\lambda v^Tv=\lambda</script></li>
  <li>至此证毕，经过投影后保存的信息量为协方差矩阵的特征值大小，而变换基为对应的特征向量。</li>
  <li>选取前k个特征值对应的特征向量组成基矩阵P</li>
  <li>则变换后的数据集为<script type="math/tex">new\_X = XP</script></li>
</ul>

:ET