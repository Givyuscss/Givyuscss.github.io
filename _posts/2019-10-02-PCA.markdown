---
layout:     post
title:      "PCA"
subtitle:   " \"PCA 原理及实现\""
date:       2019-10-2 12:00:00
author:     "Givyuscss"
header-img: "img/post-bg-js-module.jpg"
tags:
    - Machine Learning
---

## PCA

PCA主要是用于处理数据冗杂问题，功能是数据降维

### PCA数学原理
对于数据集$$X,\forall x_i \in X, x \in \mathbb{R}^d$$，每个数据都是d维的，d维特征过于冗杂，且大部分是无用的信息，因此，需要对其进行降维，提取中区分度大的特征，原数据集映射至低维空间。

需要用到的方法为基变换，一个mxn的矩阵，m个数据，每个数据n个特征，需要将其降维至k个特征，则需要n个k维基。

+ 首先向量$$x$$在$$\vec{v}$$方向上的投影为：

$$\rho(x)=\frac{\vec{v}^Tx}{\|\vec{v}\|}$$

+ 当$\vec{v}$是单位向量时，则投影为：

$$\rho(x)=\vec{v}^Tx$$

+ 设数据集为$$X_{m\times n}$$,可将变化后的投影集体设为$$Xv$$，在各个方向上的投影点越分散，方差越大，则说明这个特征对与数据集保存的信息量越多
+ 在此之前，数据集每列特征进行去均值化处理，所以使得$$\mu(X,v)=0$$
+ 而经过投影变化后的信息量为:

$$info(X,v)=\sigma^2(X,v)=\frac{1}{m}\sum^{m}_{i=1}(v^Tx_i-\mu)^2=\frac{1}{m}(Xv)^TXv=\frac{1}{m}v^TX^TXv$$

+ 由于$$X$$是去均值后的矩阵，$$\frac{1}{m}X^TX$$即为$$X$$的协方差矩阵，记为C,则$$info(X,v)=v^TCv$$
+ 又因为约束条件为$$v$$为单位向量，所以$$v^Tv=1$$，用拉格朗日乘子法将约束直接加入目标函数，则:

$$info(X,v)=v^TCv-\lambda(v^Tv-1)$$

+ 对$$info(X,v)求v偏导$$，则:

$$\frac{\partial info(X,v)}{\partial v}=2Cv-2\lambda v=0$$

&emsp;&emsp;&emsp; 则$$Cv=\lambda v$$

+ 该式符合矩阵特征值和特征向量的性质，可以的出此时满足条件的$$\lambda,v$$即为协方差矩阵的特征值和对应的特征向量。
+ 将其带入$$info(X,v)=v^TCv$$得到$$info(X,v)=v^T\lambda v=\lambda v^Tv=\lambda$$
+ 至此证毕，经过投影后保存的信息量为协方差矩阵的特征值大小，而变换基为对应的特征向量。
+ 选取前k个特征值对应的特征向量组成基矩阵P
+ 则变换后的数据集为$$new\_X = XP$$

### 实例

lris数据集包含150个数据集，分为3类Setosa(山鸢尾)，Versicolour(变色鸢尾)，Virginica（维吉尼亚鸢尾），每类50个数据，每个数据包含4个属性花萼长度，花萼宽度，花瓣长度，花瓣宽度（sepal length，sepal width ，petal length ，petal width ）。

部分数据形式如下：
<img src="/img/in-post/PCA/1.png" width="400px" height="275px"/>

PCA算法步骤：
1. 对数据进行标准化，特征的均值标准化为0，方差标准化为1
2. 计算特征的协方差矩阵CovMat
3. 计算协方差矩阵的特征值eigval和对应的eigvec
4. 选取前k个大的eigval所对应的eigvec作为基组成转换矩阵
5. 将转换矩阵与原数据矩阵相乘得到降维结果

代码实现：
```python
import pandas as pd
import matplotlib.pyplot as plt

data = pd.read_csv('iris.csv',index_col=0)
data = data.values

labels = data[:,4]
data = data[:,:4]

import numpy as np
meanvalue = np.mean(data)
std = np.std(data)
meanremove = (data - meanvalue)/std
meanremove = np.matrix(meanremove,dtype='float64')
covMat = np.cov(meanremove,rowvar=0)

eigval,eigvec = np.linalg.eig(covMat)
tmpeig = eigval.copy()

def chose_k(val):#从大到小排列特征值，取累计占比超过95%的前k个特征
    total = val.sum()
    length = len(val)
    val.sort()
    val = val[::-1]
    p = [(val[:i+1].sum()/total) for i in range(length)]
    for i in range(length):
        print("第%d特征所占比例为:%f"%(i+1,p[i]))
        if p[i] > 0.95:
            print("前%d个特征所占比已超过0.95"%(i+1))
            break
    return i+1

k = chose_k(tmpeig)
eigind = eigval.argsort()
eigind = eigind[:-(k+1):-1]
P = eigvec[:,eigind]
new_data = np.mat(meanremove)*np.mat(P)

def color():#生成3个类别的标签所对应的颜色
    co = []
    for i in range(3):
        tmp = [np.random.randint(0,255)/255.0,np.random.randint(0,255)/255.0,np.random.randint(0,255)/255.0]
        for j in range(50):
            co.append(tmp)
    return co 

co = color()
plt.scatter(np.array(new_data[:,0]),np.array(new_data[:,1]),c=co)#可视化
plt.show()
```

可视化结果为：

<img src="/img/in-post/PCA/2.png" width="400px" height="275px"/>、

[获取数据](https://github.com/Givyuscss/Givyuscss.github.io/tree/master/code/PCA_datasets "code and data")
